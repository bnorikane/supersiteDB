{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create supersite locations list\n",
    "## create list of all potential supersite venues\n",
    "- Standardize supersite venue names (e.g. \"Boulder HS\")\n",
    "- Standardize supersite columns\n",
    "    - venue (standard name of site, e.g. \"Boulder HS\")\n",
    "    - ssid (unique code for venue)\n",
    "    - address\n",
    "    - organization (name of organization that owns venue)\n",
    "    - geometry (geopandas geometry column, e.g. Point (-105.345678,40.123456))\n",
    "    - lat (latitude)\n",
    "    - lon (longitude)\n",
    "- Combine lists of known supersites\n",
    "    - 2024 supersites\n",
    "    - 2024 alternate supersites\n",
    "    - 2020 supersites\n",
    "- Save Supersite list to file or database\n",
    "    - supersite_venues.geojson\n",
    "    - supersite_venues.xlsx\n",
    "\n",
    "## Create 2024 Supersite locations file\n",
    "- Read Judi's file: data/2024_Supersite_list w Chairs & Cochairs.xlsx\n",
    "- Add geolocations for each Supersite\n",
    "- Write supersite locations geojson for map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import supersites as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create list of all potential supersites\n",
    "- Standardize supersite names\n",
    "- Standardize supersite columns\n",
    "- Combine lists of known supersites\n",
    "    - 2024 supersites\n",
    "    - 2024 alternate supersites\n",
    "    - 2020 supersites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of 2024 supersites: ss_short_2024.geojson\n",
    "ss2024 = gpd.read_file('data/ss_short_2024.geojson', driver='GEOJSON')\n",
    "\n",
    "# get list of other potential supersites ss_short_2024_alternate.geojson\n",
    "ssalt = gpd.read_file('data/ss_short_2024_alternate.geojson', driver='GEOJSON')\n",
    "\n",
    "# combine all rows in ss2024 and ssalt\n",
    "ssall = pd.concat([ss2024, ssalt]).sort_values('Venue').reset_index(drop=True)\n",
    "\n",
    "# add lat and lon columns to ssall\n",
    "ssall[['lat', 'lon']] = np.NaN\n",
    "\n",
    "ssall.info()\n",
    "ssall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssall.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ssall to supersites in 2024 supersite lists\n",
    "- Read Judi's supersite spreadsheet\n",
    "- Merge locations from ssall\n",
    "- check for missing supersites\n",
    "- create file of missing supersites\n",
    "- add lat and lon columns for missing supersites\n",
    "- create GeoDataFrame of missing supersites\n",
    "- append missing supersites to ssall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Judi's supersite file\n",
    "\n",
    "supersite_input = 'data/2024_Supersite_list w Chairs & Cochairs.xlsx' # 1/13/2024\n",
    "sheetname ='Recap SS & Precinct #s'\n",
    "\n",
    "supersites = (ss.read_supersite_pct(supersite_input, sheetname)\n",
    "              .assign(supersite=lambda df: df['supersite'].str.strip() )\n",
    ")\n",
    "supersites.info()\n",
    "supersites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add locations for each 2024 supersite\n",
    "- add supersite location geometry column to supersites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge supersites DataFrame with ssall GeoDataFrame\n",
    "\n",
    "ss_locations = pd.merge(supersites, ssall, left_on='supersite', right_on='Venue', how='left')\n",
    "ss_locations.info()\n",
    "ss_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ss_locations to excel file to add geolocations for missing venues\n",
    "ss_locations.to_excel('data/ss_locations.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add missing supersite geometries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get geometry for 2024 Supersites that are missing in ssall\n",
    "ssmissing = pd.read_excel('data/ss_locations_missing.xlsx', sheet_name='missingVenues', skiprows=0,  ).dropna()\n",
    "\n",
    "\n",
    "ssmissing.info()\n",
    "ssmissing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssmissinggdf = gpd.GeoDataFrame(ssmissing, geometry=gpd.points_from_xy(ssmissing['lon'], ssmissing['lat']), crs='EPSG:4326' )\n",
    "\n",
    "ssmissinggdf.info()\n",
    "ssmissinggdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssmissinggdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new supersites to ssall\n",
    "\n",
    "dropcols = ['Column1', 'supersite', 'dems',\n",
    "       'attendee_forecast', 'total_precincts', 'pctlist']\n",
    "\n",
    "ssall = pd.concat([ssall, ssmissinggdf]).drop(columns=dropcols).sort_values('Venue').reset_index(drop=True)\n",
    "\n",
    "ssall.info()\n",
    "ssall\n",
    "# POINT(-105.10862252002309 40.1466293875446 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing lat and long to ssall\n",
    "ssall = ssall.assign(\n",
    "    lon=ssall['geometry'].x,\n",
    "    lat=ssall['geometry'].y\n",
    ")\n",
    "\n",
    "ssall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssallgdf = gpd.GeoDataFrame(ssall, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "ssallgdf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssallgdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ssallgdf.to_file('data/supersite_venues.geojson', driver='GeoJSON', index=False)\n",
    "\n",
    "ssallgdf.to_excel('data/supersite_venues.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geop12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
